RFI Analyzer - Phonological Assessment Tool
Video Demo: https://www.youtube.com/watch?v=O27_-lmzlG0
Description:
The RFI Analyzer is a web application for assessing children's phonological development, inspired by my experience as a primary school teacher specializing in speech therapy. For years, I used paper-based tests like the Registro Fonológico Inducido (RFI) to evaluate how children pronounced 50 Spanish words, identifying errors such as omissions or substitutions. This process was manual and inefficient—transcribing responses, analyzing phonemes, and generating reports took hours. Missing an online version after leaving teaching, I built RFI Analyzer to digitize this tool. It allows users to input spontaneous and repetition responses, analyzes errors (e.g., "bruja" → "buja" detects "Omission in position 2: r"), calculates accuracy percentages, and exports PDF reports. With optional registration via SQLite, responsive design, and Flask backend, it's accessible for therapists worldwide. The open-source code on GitHub promotes community contributions.
The project structure is modular for maintainability. app.py is the core Flask app, handling routes: / redirects to /register for user signup; /register (GET/POST) processes registration with bcrypt-hashed passwords stored in users.db; /index renders the assessment form; /analizar processes inputs using comparar_fonemas to compare against a phoneme dictionary (fonemas), storing results in session; /descargar_pdf generates PDFs with ReportLab. I chose SQLite for its simplicity—no server setup needed—and bcrypt for secure password storage. The phoneme analysis prioritizes omissions (common in children) over substitutions, using dynamic indexing to align sequences accurately, avoiding false positives like in early versions.
templates/register.html displays a form for name, email, and password, with flash messages for errors (e.g., duplicate email). I debated mandatory registration but added a "Continue without registration" link (<a href="/index">) to bypass validation, prioritizing usability—guests can assess without commitment. templates/index.html features a responsive table of 50 words with images (200x200px, from static/images/), inputs for spontaneous/repetition responses, and Jinja2 loops for dynamic rendering. Images engage children, a design choice from my teaching days, with onerror fallbacks for missing files.
templates/results.html shows a table of productions, errors, and accuracy summary (e.g., "92% spontaneous"), with a PDF download button. static/css/styles.css ensures consistency: green buttons (#4CAF50), centered headers, and media queries for mobile stacking. requirements.txt lists dependencies (Flask, bcrypt, ReportLab) for easy setup.
Design choices reflected practical needs. Server-side analysis in app.py ensures reliability over client-side JS. For PDF, fixed column widths ([100, 230, 230]) and Paragraph wrapping prevent overflow, addressing initial margin issues. Optional registration balances privacy and tracking; future versions could add login to link assessments to users.
Challenges included accurate phoneme comparison—early comparar_fonemas misaligned sequences (e.g., treating "buja" as substitutions). I refined it with dual indices, prioritizing omissions. SQLite setup was straightforward, but handling IntegrityErrors for duplicates required flash messaging. PDF formatting took iteration: smaller fonts (8pt) and margins (30pt) made tables legible.
Future improvements: Integrate Chart.js for accuracy graphs, store assessments in SQLite linked to users, and add intervention suggestions (e.g., "/r/ exercises"). This project transformed my classroom frustration into a digital solution, making phonological assessments faster and shareable.
